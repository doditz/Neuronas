{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronas AI Benchmarking - Environment Setup Example\n",
    "\n",
    "This notebook demonstrates how to set up and validate your environment for AI benchmarking with the Neuronas repository.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Setup](#environment-setup)\n",
    "2. [Dependency Verification](#dependency-verification)\n",
    "3. [Resource Availability](#resource-availability)\n",
    "4. [Dataset Loading Examples](#dataset-loading-examples)\n",
    "5. [Basic AI Model Examples](#basic-ai-model-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, let's check our Python environment and install any missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Check if we're running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if in Colab or if packages are missing\n",
    "try:\n",
    "    import numpy\n",
    "    print(\"✓ Dependencies already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing dependencies...\")\n",
    "    if IN_COLAB:\n",
    "        !pip install -q -r requirements.txt\n",
    "    else:\n",
    "        print(\"Please run: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Verification\n",
    "\n",
    "Let's verify that all key dependencies are available and check their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def check_package(package_name: str, import_name: str = None) -> Optional[str]:\n",
    "    \"\"\"Check if a package is available and return its version.\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(import_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"✓ {package_name}: {version}\")\n",
    "        return version\n",
    "    except ImportError:\n",
    "        print(f\"✗ {package_name}: Not available\")\n",
    "        return None\n",
    "\n",
    "# Check core dependencies\n",
    "packages = {\n",
    "    'NumPy': 'numpy',\n",
    "    'Pandas': 'pandas', \n",
    "    'Scikit-learn': 'sklearn',\n",
    "    'Matplotlib': 'matplotlib',\n",
    "    'PyTorch': 'torch',\n",
    "    'TensorFlow': 'tensorflow',\n",
    "    'Transformers': 'transformers',\n",
    "    'Datasets': 'datasets',\n",
    "    'Qiskit': 'qiskit',\n",
    "    'Jupyter': 'jupyter'\n",
    "}\n",
    "\n",
    "print(\"Package Versions:\")\n",
    "print(\"=\" * 40)\n",
    "for display_name, import_name in packages.items():\n",
    "    check_package(display_name, import_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Availability\n",
    "\n",
    "Check system resources and hardware acceleration availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "def check_gpu_resources():\n",
    "    \"\"\"Check for GPU availability across different frameworks.\"\"\"\n",
    "    print(\"GPU Resource Check:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # PyTorch CUDA check\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            print(f\"✓ PyTorch CUDA: {gpu_count} GPU(s) - {gpu_name}\")\n",
    "            print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "        else:\n",
    "            print(\"○ PyTorch CUDA: Not available (CPU mode)\")\n",
    "    except ImportError:\n",
    "        print(\"✗ PyTorch: Not installed\")\n",
    "    \n",
    "    # TensorFlow GPU check\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            print(f\"✓ TensorFlow GPU: {len(gpus)} GPU(s) detected\")\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                print(f\"  GPU {i}: {gpu.name}\")\n",
    "        else:\n",
    "            print(\"○ TensorFlow GPU: Not available (CPU mode)\")\n",
    "    except ImportError:\n",
    "        print(\"✗ TensorFlow: Not installed\")\n",
    "\n",
    "check_gpu_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system memory\n",
    "try:\n",
    "    import psutil\n",
    "    \n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"\\nSystem Memory:\")\n",
    "    print(f\"Total: {memory.total / (1024**3):.1f} GB\")\n",
    "    print(f\"Available: {memory.available / (1024**3):.1f} GB\")\n",
    "    print(f\"Usage: {memory.percent}%\")\n",
    "    \n",
    "    # CPU info\n",
    "    print(f\"\\nCPU Cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count(logical=True)} logical\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"psutil not available - cannot check system resources\")\n",
    "    # Fallback using basic Python\n",
    "    import os\n",
    "    print(f\"CPU count (logical): {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading Examples\n",
    "\n",
    "Demonstrate loading datasets for different AI tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Load a simple dataset using scikit-learn\n",
    "try:\n",
    "    from sklearn.datasets import load_iris, load_digits\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Loading Iris dataset...\")\n",
    "    iris = load_iris()\n",
    "    print(f\"✓ Iris dataset loaded: {iris.data.shape} samples\")\n",
    "    print(f\"  Features: {len(iris.feature_names)}\")\n",
    "    print(f\"  Classes: {len(iris.target_names)}\")\n",
    "    \n",
    "    print(\"\\nLoading Digits dataset...\")\n",
    "    digits = load_digits()\n",
    "    print(f\"✓ Digits dataset loaded: {digits.data.shape} samples\")\n",
    "    print(f\"  Image size: {digits.images[0].shape}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot load sklearn datasets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Load dataset using Hugging Face datasets (if available)\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    \n",
    "    print(\"Loading sample dataset from Hugging Face...\")\n",
    "    # Load a small, quick dataset for demonstration\n",
    "    dataset = load_dataset(\"imdb\", split=\"train[:100]\")  # Just first 100 samples\n",
    "    print(f\"✓ IMDB dataset sample loaded: {len(dataset)} samples\")\n",
    "    print(f\"  Features: {list(dataset.features.keys())}\")\n",
    "    \n",
    "    # Show a sample\n",
    "    print(f\"\\nSample text (truncated): {dataset[0]['text'][:100]}...\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"✗ Hugging Face datasets not available\")\n",
    "except Exception as e:\n",
    "    print(f\"○ Could not load Hugging Face dataset (may require internet): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic AI Model Examples\n",
    "\n",
    "Demonstrate basic AI model functionality with the available frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple scikit-learn model\n",
    "try:\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    print(\"Training a simple Random Forest classifier...\")\n",
    "    \n",
    "    # Load data\n",
    "    iris = load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"✓ Model trained successfully!\")\n",
    "    print(f\"  Training samples: {len(X_train)}\")\n",
    "    print(f\"  Test samples: {len(X_test)}\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot run scikit-learn example: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Simple PyTorch tensor operations\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    \n",
    "    print(\"Testing PyTorch tensor operations...\")\n",
    "    \n",
    "    # Create random tensors\n",
    "    x = torch.randn(3, 4)\n",
    "    y = torch.randn(4, 2)\n",
    "    \n",
    "    # Matrix multiplication\n",
    "    z = torch.mm(x, y)\n",
    "    \n",
    "    print(f\"✓ PyTorch operations successful!\")\n",
    "    print(f\"  Input tensor shape: {x.shape}\")\n",
    "    print(f\"  Weight tensor shape: {y.shape}\")\n",
    "    print(f\"  Output tensor shape: {z.shape}\")\n",
    "    print(f\"  Device: {z.device}\")\n",
    "    \n",
    "    # Simple neural network\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(4, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 3)\n",
    "    )\n",
    "    \n",
    "    output = model(x)\n",
    "    print(f\"  Neural network output shape: {output.shape}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot run PyTorch example: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Simple TensorFlow operations  \n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    print(\"Testing TensorFlow operations...\")\n",
    "    \n",
    "    # Create random tensors\n",
    "    x = tf.random.normal([3, 4])\n",
    "    y = tf.random.normal([4, 2])\n",
    "    \n",
    "    # Matrix multiplication\n",
    "    z = tf.matmul(x, y)\n",
    "    \n",
    "    print(f\"✓ TensorFlow operations successful!\")\n",
    "    print(f\"  Input tensor shape: {x.shape}\")\n",
    "    print(f\"  Weight tensor shape: {y.shape}\")\n",
    "    print(f\"  Output tensor shape: {z.shape}\")\n",
    "    \n",
    "    # Simple neural network\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(8, activation='relu', input_shape=(4,)),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    \n",
    "    output = model(x)\n",
    "    print(f\"  Neural network output shape: {output.shape}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"✗ Cannot run TensorFlow example: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Summary\n",
    "\n",
    "Run the complete environment validation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the validation script from the validation directory\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the repository root to the path\n",
    "repo_root = os.path.abspath('..')  # Assuming notebook is in notebooks/ subdirectory\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "try:\n",
    "    from validation.validate_environment import run_validation\n",
    "    \n",
    "    print(\"Running complete environment validation...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    success = run_validation()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 Environment is ready for AI benchmarking!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  Some validation checks failed. Please review the output above.\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"Cannot import validation module: {e}\")\n",
    "    print(\"Please ensure you're running from the correct directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If your environment validation was successful, you're ready to:\n",
    "\n",
    "1. **Explore AI Benchmarks**: Check out other notebooks in the `/notebooks/` directory\n",
    "2. **Load Datasets**: Use the scripts in `/datasets/` to download and prepare data\n",
    "3. **Run Tests**: Execute `pytest tests/` to run the full test suite\n",
    "4. **Contribute**: Follow the guidelines in `.github/copilot-instructions.md`\n",
    "\n",
    "### Useful Commands\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run environment validation\n",
    "python validation/validate_environment.py\n",
    "\n",
    "# Run tests\n",
    "pytest tests/ -v\n",
    "\n",
    "# Format code\n",
    "black .\n",
    "\n",
    "# Lint code\n",
    "flake8 .\n",
    "```\n",
    "\n",
    "Happy benchmarking! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}